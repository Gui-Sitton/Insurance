{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A companhia de seguros Proteja Seu Amanhã quer resolver algumas tarefas com a ajuda de aprendizado de máquina e você precisa avaliar a possibilidade de fazê-lo.\n",
    "\n",
    "- Tarefa 1: Encontrar clientes semelhantes a um determinado cliente. Isso vai ajudar os agentes da empresa com tarefas de marketing.\n",
    "- Tarefa 2: Predizer se um novo cliente provavelmente receberá um pagamento de seguro. Um modelo de predição pode ser melhor do que um modelo dummy?\n",
    "- Tarefa 3: Predizer o número de pagamentos de seguro que um novo cliente provavelmente receberá usando um modelo de regressão linear.\n",
    "- Tarefa 4: Proteger os dados pessoais dos clientes sem estragar o modelo da tarefa anterior. É necessário desenvolver um algoritmo de transformação de dados que tornaria difícil recuperar informações pessoais se os dados caíssem nas mãos erradas. Isso é chamado de mascaramento de dados ou ofuscação de dados. Mas os dados devem ser protegidos de forma que a qualidade dos modelos de aprendizado de máquina não piore. Você não precisa escolher o melhor modelo, só prove que o algoritmo funciona corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento de dados & Exploração\n",
    "\n",
    "## Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 9.8 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.17.3\n",
      "  Downloading numpy-1.25.2-cp311-cp311-win_amd64.whl (15.5 MB)\n",
      "     --------------------------------------- 15.5/15.5 MB 27.3 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.11.2-cp311-cp311-win_amd64.whl (44.0 MB)\n",
      "     --------------------------------------- 44.0/44.0 MB 50.4 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.3.2 numpy-1.25.2 scikit-learn-1.3.0 scipy-1.11.2 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import distance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregue os dados e faça uma verificação básica de que estão livres de problemas óbvios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/insurance_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renomeamos as colunas para tornar o código mais consistente com seu estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos querer corrigir o tipo de idade (de float para int), embora isso não seja crítico\n",
    "\n",
    "# escreva sua conversão aqui se você escolher:\n",
    "\n",
    "df['age'] = df['age'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifique se a conversão foi bem-sucedida\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora dê uma olhada nas estatísticas descritivas dos dados.\n",
    "# Parece que está tudo bem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aparentemente a coluna insurance_benefits tem muitos outliars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Utilizei o drop_duplicated pois não 153 linhas são insignificante em um dataframe de 5000 linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar rapidamente se existem determinados grupos de clientes observando o gráfico de pares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, kind='hist')\n",
    "g.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(df,x='age',y='income',z='insurance_benefits', color = 'family_members')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos ver uma relação em que o grupo que mais recebe insurance benefits é o grupo mais velho acima de 40 anos, com uma relação de estreitamento em direção a 'média' com o income, conforme a idade aumenta os selecionados estão mais no meio ainda. E com poucos membros na família. Obviamente levando em conta uma igualdade de gêneros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O que se confirma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, é um pouco difícil identificar grupos óbvios (clusters), pois é difícil combinar várias variáveis simultaneamente (para analisar distribuições multivariadas). É aí que Álgebra Linear e Aprendizado de Máquina podem ser bastante úteis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 1. Clientes Similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na linguagem de AM, é necessário desenvolver um procedimento que retorne k vizinhos mais próximos (objetos) para um determinado objeto com base na distância entre os objetos.\n",
    "Você pode querer rever as seguintes lições (capítulo -> lição)- Distância Entre Vetores -> Distância Euclidiana\n",
    "- Distância Entre Vetores -> Distância de Manhattan\n",
    "\n",
    "Para resolver a tarefa, podemos tentar diferentes métricas de distância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escreva uma função que retorne k vizinhos mais próximos para um n-ésimo objeto com base em uma métrica de distância especificada. O número de pagamentos de seguro recebidos não deve ser levado em consideração para esta tarefa. \n",
    "\n",
    "Você pode usar uma implementação pronta do algoritmo kNN do scikit-learn (verifique [o link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)) ou usar a sua própria.\n",
    "Teste-o para quatro combinações de dois casos\n",
    "- Escalabilidade\n",
    "  - os dados não são escalados\n",
    "  - os dados escalados com o escalonador [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html) \n",
    "- Métricas de distância\n",
    "  - Euclidiana\n",
    "  - Manhattan\n",
    "\n",
    "Responda às perguntas:\n",
    "- Os dados não escalados afetam o algoritmo kNN? Se sim, como isso acontece?\n",
    "-Quão semelhantes são os resultados usando a métrica de distância de Manhattan (independentemente da escalabilidade)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(df, n, k, metric):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retorna os vizinhos mais próximos de k\n",
    "\n",
    "    :param df: DataFrame pandas usado para encontrar objetos semelhantes dentro de    :param n: número do objeto pelo qual os vizinhos mais próximos são procurados\n",
    "    :param k: o número dos vizinhos mais próximos a serem retornados\n",
    "    :param metric: nome da métrica de distância    \"\"\"\n",
    "    \n",
    "    if metric == 'euclidean':\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "    elif metric == 'manhattan':\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, metric='manhattan')\n",
    "    else:\n",
    "        raise ValueError(\"Métrica não suportada. Escolha 'euclidean' ou 'manhattan'\")\n",
    "\n",
    "   \n",
    "    nbrs = nbrs.fit(df[feature_names])\n",
    "   \n",
    "    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)\n",
    "    \n",
    "    df_res = pd.concat([\n",
    "        df.iloc[nbrs_indices[0]], \n",
    "        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])\n",
    "        ], axis=1)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']\n",
    "\n",
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos obter registros semelhantes para um determinado registro para cada combinação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df, 1, 10, 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df, 1, 10, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df_scaled, 1, 10, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df_scaled, 1, 10, 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respostas para as perguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Os dados não escalados afetam o algoritmo kNN? Se sim, como isso acontece?** \n",
    "\n",
    "Afetam sim, deixando a distância calculada maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As diferenças de escala podem levar a uma maior influência de algumas características em relação a outras. Por exemplo, se uma característica tiver valores muito maiores em comparação com outras, ela dominará as distâncias calculadas pelo kNN, mesmo que outras características sejam mais relevantes para a tarefa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quão semelhantes são os resultados usando a métrica de distância de Manhattan (independentemente da escalabilidade)?** \n",
    "\n",
    "Bem semelhantes, mas maiores que a distância euclidiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 2. É provável que o cliente receba um pagamento do seguro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos de aprendizado de máquina, podemos olhar para isso como uma tarefa de classificação binária."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os pagamentos de seguro sendo mais do que zero como objetivo, avalie se a abordagem da classificação kNN pode ser melhor do que um modelo dummy.\n",
    "\n",
    "Instruções:\n",
    "- Construa um classificador baseado em kNN e meça sua qualidade com a métrica F1 para k=1..10 tanto para os dados originais quanto para os escalados. Seria interessante ver como k pode influenciar a métrica de avaliação e se a escalabilidade dos dados faz alguma diferença. Você pode usar uma implementação pronta do algoritmo de classificação kNN do scikit-learn (verifique [o link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) ou usar a sua própria.\n",
    "- Construa o modelo dummy, que é aleatório para este caso. Deve retornar com alguma probabilidade o valor \"1\". LVamos testar o modelo com quatro valores de probabilidade: 0, a probabilidade de fazer qualquer pagamento de seguro, 0,5, 1.\n",
    "\n",
    "A probabilidade de fazer qualquer pagamento de seguro pode ser definida como\n",
    "\n",
    "$$\n",
    "P\\{\\text{pagamento de seguro recebido}= número de clientes que receberam qualquer pagamento de seguro}}{\\text{número total de clientes}}.\n",
    "$$\n",
    "\n",
    "Divida os dados inteiros na proporção 70:30 para as partes de treinamento/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(insurance_benefits):\n",
    "    if insurance_benefits >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['insurance_benefits_received'] = df['insurance_benefits'].apply(update)\n",
    "df_scaled['insurance_benefits_received'] = df_scaled['insurance_benefits'].apply(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifique o desequilíbrio de classe com value_counts()\n",
    "\n",
    "display(df['insurance_benefits_received'].value_counts())\n",
    "df_scaled['insurance_benefits_received'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=12345)\n",
    "\n",
    "df_train2, df_test2 = train_test_split(df_scaled, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['insurance_benefits_received','insurance_benefits'], axis=1)\n",
    "target_train = df_train['insurance_benefits_received']\n",
    "\n",
    "features_test = df_test.drop(['insurance_benefits_received','insurance_benefits'], axis=1)\n",
    "target_test = df_test['insurance_benefits_received']\n",
    "\n",
    "features_train2 = df_train2.drop(['insurance_benefits_received','insurance_benefits'], axis=1)\n",
    "target_train2 = df_train2['insurance_benefits_received']\n",
    "\n",
    "features_test2 = df_test2.drop(['insurance_benefits_received','insurance_benefits'], axis=1)\n",
    "target_test2 = df_test2['insurance_benefits_received'] \n",
    "\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)\n",
    "\n",
    "\n",
    "print(features_train2.shape)\n",
    "print(target_train2.shape)\n",
    "print(features_test2.shape)\n",
    "print(target_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(features_train, target_train)\n",
    "    test_predictions = model.predict(features_test)\n",
    "\n",
    "    model2 = KNeighborsClassifier(n_neighbors=i)\n",
    "    model2.fit(features_train2, target_train2)\n",
    "    test_predictions2 = model2.predict(features_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "# se você tiver um problema com a linha a seguir, reinicie o kernel e execute o caderno novamente\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print('Matriz de Confusão')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando saída de um modelo aleatório\n",
    "\n",
    "def rnd_model_predict(P, size, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    return rng.binomial(n=1, p=P, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for P in [0, df['insurance_benefits_received'].sum() / len(df), 0.5, 1]:\n",
    "\n",
    "    print(f'A probabilidade: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P, size=len(df['insurance_benefits_received']))\n",
    "        \n",
    "    eval_classifier(df['insurance_benefits_received'], y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    print('k=',i)\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(features_train, target_train)\n",
    "    test_predictions = model.predict(features_test)\n",
    "    eval_classifier(target_test, test_predictions)\n",
    "    print('k scaled=',i)\n",
    "    model2 = KNeighborsClassifier(n_neighbors=i)\n",
    "    model2.fit(features_train2, target_train2)\n",
    "    test_predictions2 = model2.predict(features_test2)\n",
    "    eval_classifier(target_test2, test_predictions2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O maior valor f1 encontrado foi com o parâmetro k=1 com os dados *scaled*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 3. Regressão (com Regressão Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os pagamentos de seguro como objetivo, avalie qual seria o REQM para um modelo de Regressão Linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construa sua própria implementação de Regressão Linear. Para isso, lembre-se de como a solução da tarefa de regressão linear é formulada em termos de Álgebra linear. Verifique o REQM para os dados originais e os escalados. Você pode ver alguma diferença no REQM entre esses dois casos?\n",
    "\n",
    "Vamos denotar\n",
    "- $X$ — matriz de características, cada linha é um caso, cada coluna é uma característica, a primeira coluna consiste em unidades\n",
    "- $y$ — objetivo (um vetor)\n",
    "- $\\hat{y}$ — objetivo estimado (um vetor)- $w$ — vetor de peso\n",
    "\n",
    "A tarefa de regressão linear na linguagem de matrizes pode ser formulada como\n",
    "$$\n",
    "y = Xw\n",
    "$$\n",
    "\n",
    "O objetivo do treinamento, então, é encontrar os $w$ que minimizaria a distância L2 (EQM) entre $Xw$ e $y$:\n",
    "\n",
    "$$\n",
    "\\min_w d_2(Xw, y) \\quad \\text{or} \\quad \\min_w \\text{MSE}(Xw, y)\n",
    "$$\n",
    "\n",
    "Parece que há uma solução analítica para a questão acima:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "A fórmula acima pode ser usada para encontrar os pesos $w$ e o último pode ser usado para calcular valores preditos\n",
    "\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divida todos os dados na proporção 70:30 para as partes de treinamento/validação. Use a métrica REQM para a avaliação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Adicionando uma coluna de uns para representar o termo de bias\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        \n",
    "        # Calculando os pesos usando a fórmula dos mínimos quadrados\n",
    "        self.weights = np.linalg.inv(X2.T @ X2) @ X2.T @ y\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Adicionando uma coluna de uns para representar o termo de bias\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        \n",
    "        # Realizando a previsão usando os pesos aprendidos\n",
    "        y_pred = X2 @ self.weights\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'REQM: {rmse:.2f}')\n",
    "    \n",
    "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "    print(f'R2: {r2_score:.2f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xx, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xxx = df_scaled[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "yx = df_scaled['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_trainx, X_testx, y_trainx, y_testx = train_test_split(Xxx, yx, test_size=0.3, random_state=12345)\n",
    "\n",
    "lrx = MyLinearRegression()\n",
    "\n",
    "lrx.fit(X_trainx, y_trainx)\n",
    "print(lrx.weights)\n",
    "\n",
    "y_test_predx = lrx.predict(X_testx)\n",
    "eval_regressor(y_testx, y_test_predx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sem diferença no REQM nesses dois casos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 4. Ofuscando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É melhor ofuscar os dados multiplicando as características numéricas (lembre-se, elas podem ser vistos como a matriz $X$) por uma matriz invertível $P$. \n",
    "\n",
    "$$\n",
    "X' = X \\times P\n",
    "$$\n",
    "\n",
    "Tente fazer isso e verifique como os valores das características ficarão após a transformação. Aliás, a invertibilidade é importante aqui, portanto, certifique-se de que $P$ seja realmente invertível.\n",
    "\n",
    "Você pode querer revisar a lição 'Matrizes e Operações com Matrizes -> Multiplicação de Matrizes' para relembrar a regra de multiplicação de matrizes e sua implementação com NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz original\n",
    "X = df_pn.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando uma matriz $P$ aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz aleatoria\n",
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando se a matriz $P$ é invertível"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=np.linalg.inv(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você consegue adivinhar a idade ou a renda dos clientes após a transformação?\n",
    "* Não"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz transformada\n",
    "X1=X @ P\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode recuperar os dados originais de $X′$ se souber $P$? Tente verificar isso com cálculos movendo $P$ do lado direito da fórmula acima para o esquerdo. As regras da multiplicação de matrizes são realmente úteis aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XX=X1 @ p1\n",
    "XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima todos os três casos para alguns clientes- Os dados originais\n",
    "- O transformado\n",
    "- O invertido (recuperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(X,X1,XX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você provavelmente pode ver que alguns valores não são exatamente iguais aos dos dados originais. Qual pode ser a razão disso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Acredito que se deve à natureza das transformações aplicadas e à complexidade dos algoritmos envolvidos. Por se tratar de uma matriz aleatória na ofuscação e a inversa dela na recuperação. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provas de que a ofuscação de dados pode funcionar com a Regressão Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tarefa de regressão foi resolvida com regressão linear neste projeto. Sua próxima tarefa é provar analiticamente que o método de ofuscação fornecido não afetará a regressão linear em termos de valores preditos, ou seja, seus valores permanecerão os mesmos. Você acredita nisso? Bem, você não precisa acreditar, você deve provar isso!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, os dados são ofuscados e há $X \\ P$ em vez de apenas X agora. Consequentemente, existem outros pesos $w_P$ como\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y \\quad \\Rightarrow \\quad w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$\n",
    "\n",
    "Como  $w$ e $w_P$ seriam ligados se você simplificasse a fórmula para $w_P$ acima? \n",
    "\n",
    "Quais seriam os valores previstos com $w_P$? \n",
    "\n",
    "O que isso significa para a qualidade da regressão linear se você medir com REQM?\n",
    "\n",
    "Verifique o Apêndice B Propriedades das Matrizes no final do caderno. Existem fórmulas úteis lá!\n",
    "\n",
    "Nenhum código é necessário nesta seção, apenas explicação analítica!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Para simplificar essa fórmula, podemos usar a propriedade das matrizes que diz que <td>$(AB)^T = B^TA^T$</td>. Aplicando isso, podemos reescrever 𝑤𝑃 como <td>$$𝑤𝑃=(𝑋𝑃)^{-1}(𝑋𝑃)^𝑇𝑦$$</td>.\n",
    "\n",
    "2- Para calcular os valores previstos com 𝑤𝑃, você multiplica a matriz de características 𝑋𝑃 pelos pesos 𝑤𝑃. Ou seja, os valores previstos 𝑦̂𝑃 seriam <td>$$𝑦̂𝑃=𝑋𝑃𝑤𝑃$$</td>.\n",
    "\n",
    "3- O REQM (Raiz do Erro Quadrático Médio) é uma medida comum de qualidade para avaliar a eficácia de um modelo de regressão. Portanto, se o REQM for menor, significa que os valores previstos estão mais próximos dos valores reais, o que indica uma melhor qualidade da regressão linear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prova analítica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td>\n",
    "$$\n",
    "w=(X^{T}X)^{-1}X^{T}y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = [(XP)^{T}(XP)]^{-1}(XP)^{T}y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = [(P^{T}X^{T})(XP)]^{-1}(XP)^{T}y,\n",
    "$$\n",
    "\n",
    "Usando a propriedade de reversividade da transposição de um produto de matrizes, assim conseguimos passar de $(XP)^{T}$ para $(P^{T}X^{T})$.\n",
    "\n",
    "Após esse passo, podemos aplicar a inversa num produto matricial junto da propriedade associativa da multiplicação,\n",
    "\n",
    "$$\n",
    "w_P = [P^{T}(X^{T}X)P]^{-1}(XP)^{T}y = P^{-1}(X^{T}X)^{-1}(P^{T})^{-1}P^{T}(X^{T}y).\n",
    "$$\n",
    "    \n",
    "Antes do termo $(X^{T}y)$ temos o termo $(P^{T})^{-1}P^{T}$, porém pela propriedade da identidade multiplicativa, temos que:\n",
    "    \n",
    "$$\n",
    "(P^{T})^{-1}P^{T} = I,\n",
    "$$\n",
    "\n",
    "Continuando:\n",
    "​\n",
    "$$\n",
    "w_P = P^{-1}(X^{T}X)^{-1}(P^{T})^{-1}P^{T}(X^{T}y) = P^{-1}(X^{T}X)^{-1}I(X^{T}y) = P^{-1}(X^{T}X)^{-1}(X^{T}y).\n",
    "$$\n",
    "    \n",
    "Bem, se $w = (X^{T}X)^{-1}X^{T}y$, então:\n",
    "    \n",
    "$$\n",
    "w_P = P^{-1}(X^{T}X)^{-1}(X^{T}y) = P^{-1}w,\n",
    "$$\n",
    "    \n",
    "logo a matriz $A$ desconhecida é igual a $P^{-1}$ e:\n",
    "    \n",
    "$$\n",
    "w_P = P^{-1}w.\n",
    "$$\n",
    "​\n",
    "Para demonstrar de forma analítica que a ofuscação de dados não afeta a regressão linear, é suficiente substituir o valor de 𝑤𝑃\n",
    "na equação a seguir pela relação previamente estabelecida:\n",
    "    \n",
    "$$\n",
    "\\hat{y_P} = (X_{val}P)w_P = X_{val}PP^{-1}w,\n",
    "$$\n",
    "    \n",
    "pela propriedade da identidade multiplicativa, temos que:\n",
    "​\n",
    "$$\n",
    "\\hat{y_P} = X_{val}PP^{-1}w = X_{val}Iw = X_{val}w = \\hat{y}.\n",
    "$$\n",
    "    \n",
    "Assim, demonstramos que $\\hat{y_P} = \\hat{y}$, o que implica que a ofuscação de dados não tem efeito sobre a previsão realizada, embora possa modificar os coeficientes estimados. Como resultado, uma vez que a previsão permanece inalterada, nenhuma métrica de erro sofrerá modificação.\n",
    "</td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_w(X, y):\n",
    "    XTX_inv = np.linalg.inv(np.dot(X.T, X))\n",
    "    w = np.dot(np.dot(XTX_inv, X.T), y)\n",
    "    return w\n",
    "\n",
    "def calculate_wP(XP, y):\n",
    "    wP = np.dot(np.dot(np.linalg.inv(np.dot(XP.T, XP)), XP.T), y)\n",
    "    return wP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "XP = Xx + 1 #ex de dados ofuscados \n",
    "\n",
    "w = calculate_w(Xx, y)\n",
    "wP = calculate_wP(XP, y)\n",
    "\n",
    "print(\"w:\", w)\n",
    "print(\"wP:\", wP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_values(X, w):\n",
    "    y_pred = np.dot(X, w)\n",
    "    return y_pred\n",
    "\n",
    "def predict_values_P(XP, wP):\n",
    "    y_pred_P = np.dot(XP, wP)\n",
    "    return y_pred_P\n",
    "\n",
    "# Exemplo de uso\n",
    "y_pred = predict_values(Xx, w)\n",
    "y_pred_P = predict_values_P(XP, wP)\n",
    "\n",
    "print(\"y_pred:\", y_pred)\n",
    "print(\"y_pred_P:\", y_pred_P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RMSE(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# Exemplo de uso\n",
    "RMSE_w = calculate_RMSE(y, y_pred)\n",
    "RMSE_wP = calculate_RMSE(y, y_pred_P)\n",
    "\n",
    "print(\"RMSE for w:\", RMSE_w)\n",
    "print(\"RMSE for wP:\", RMSE_wP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de regressão linear com ofuscação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos provar que a Regressão Linear pode funcionar computacionalmente com a transformação de ofuscação escolhida.\n",
    "Crie um procedimento ou uma classe que execute a Regressão Linear opcionalmente com a ofuscação. Você pode usar uma implementação pronta de Regressão Linear do scikit-learn ou sua própria.\n",
    "\n",
    "Execute a Regressão Linear para os dados originais e os ofuscados, compare os valores previstos e os valores da métrica $R^2$ do REQM. Há alguma diferença?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedimento**\n",
    "\n",
    "- Crie uma matriz quadrada $P$ de números aleatórios.\n",
    "- Verifique se é invertível. Caso contrário, repita o primeiro ponto até obtermos uma matriz invertível.\n",
    "- <! seu comentário aqui!>\n",
    "- Use $XP$ como a nova matriz de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev(y_true,y_pred):\n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'REQM: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=df[['age', 'gender', 'income', 'family_members']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=df_scaled[['age', 'gender', 'income', 'family_members']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "Pw = rng.random(size=(G.shape[1], G.shape[1]))\n",
    "Pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "Pb = rng.random(size=(B.shape[1], B.shape[1]))\n",
    "Pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = np.linalg.inv(Pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=np.linalg.inv(Pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo=G@oo\n",
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb=B@bb\n",
    "mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = mo\n",
    "y1 = G\n",
    "\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr1 = MyLinearRegression()\n",
    "\n",
    "lr1.fit(X_train1, y_train1)\n",
    "print(lr1.weights)\n",
    "\n",
    "ev(y_train1, lr1.predict(X_train1))\n",
    "ev(y_test1, lr1.predict(X_test1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1.fit(X_test1, y_test1)\n",
    "ev(y_train1, lr1.predict(X_train1))\n",
    "ev(y_test1, lr1.predict(X_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = mb\n",
    "y2 = B\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr2 = MyLinearRegression()\n",
    "\n",
    "lr2.fit(X_train2, y_train2)\n",
    "print(lr2.weights)\n",
    "ev(y_train2, lr2.predict(X_train2))\n",
    "ev(y_test2, lr2.predict(X_test2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.fit(X_test2, y_test2)\n",
    "ev(y_train2, lr2.predict(X_train2))\n",
    "ev(y_test2, lr2.predict(X_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Não existe grupos muito claros, porém em um gráfico 3d da para ter uma noção melhor de como o dataframe se comporta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Escalamento de dados melhora o desempenho do Knn, e normalmente de todos os testes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Prova que o REQM não muda com a ofuscação de dados foi feita."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdos ",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "364.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
