{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A companhia de seguros Proteja Seu Amanh√£ quer resolver algumas tarefas com a ajuda de aprendizado de m√°quina e voc√™ precisa avaliar a possibilidade de faz√™-lo.\n",
    "\n",
    "- Tarefa 1: Encontrar clientes semelhantes a um determinado cliente. Isso vai ajudar os agentes da empresa com tarefas de marketing.\n",
    "- Tarefa 2: Predizer se um novo cliente provavelmente receber√° um pagamento de seguro. Um modelo de predi√ß√£o pode ser melhor do que um modelo dummy?\n",
    "- Tarefa 3: Predizer o n√∫mero de pagamentos de seguro que um novo cliente provavelmente receber√° usando um modelo de regress√£o linear.\n",
    "- Tarefa 4: Proteger os dados pessoais dos clientes sem estragar o modelo da tarefa anterior. √â necess√°rio desenvolver um algoritmo de transforma√ß√£o de dados que tornaria dif√≠cil recuperar informa√ß√µes pessoais se os dados ca√≠ssem nas m√£os erradas. Isso √© chamado de mascaramento de dados ou ofusca√ß√£o de dados. Mas os dados devem ser protegidos de forma que a qualidade dos modelos de aprendizado de m√°quina n√£o piore. Voc√™ n√£o precisa escolher o melhor modelo, s√≥ prove que o algoritmo funciona corretamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pr√©-processamento de dados & Explora√ß√£o\n",
    "\n",
    "## Inicializa√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learnNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "     ---------------------------------------- 9.2/9.2 MB 9.8 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.17.3\n",
      "  Downloading numpy-1.25.2-cp311-cp311-win_amd64.whl (15.5 MB)\n",
      "     --------------------------------------- 15.5/15.5 MB 27.3 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.11.2-cp311-cp311-win_amd64.whl (44.0 MB)\n",
      "     --------------------------------------- 44.0/44.0 MB 50.4 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "     ---------------------------------------- 302.2/302.2 kB ? eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.3.2 numpy-1.25.2 scikit-learn-1.3.0 scipy-1.11.2 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import r2_score\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import distance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregue os dados e fa√ßa uma verifica√ß√£o b√°sica de que est√£o livres de problemas √≥bvios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/insurance_us.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renomeamos as colunas para tornar o c√≥digo mais consistente com seu estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Gender': 'gender', 'Age': 'age', 'Salary': 'income', 'Family members': 'family_members', 'Insurance benefits': 'insurance_benefits'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podemos querer corrigir o tipo de idade (de float para int), embora isso n√£o seja cr√≠tico\n",
    "\n",
    "# escreva sua convers√£o aqui se voc√™ escolher:\n",
    "\n",
    "df['age'] = df['age'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifique se a convers√£o foi bem-sucedida\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora d√™ uma olhada nas estat√≠sticas descritivas dos dados.\n",
    "# Parece que est√° tudo bem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Aparentemente a coluna insurance_benefits tem muitos outliars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Utilizei o drop_duplicated pois n√£o 153 linhas s√£o insignificante em um dataframe de 5000 linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar rapidamente se existem determinados grupos de clientes observando o gr√°fico de pares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.pairplot(df, kind='hist')\n",
    "g.fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_3d(df,x='age',y='income',z='insurance_benefits', color = 'family_members')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos ver uma rela√ß√£o em que o grupo que mais recebe insurance benefits √© o grupo mais velho acima de 40 anos, com uma rela√ß√£o de estreitamento em dire√ß√£o a 'm√©dia' com o income, conforme a idade aumenta os selecionados est√£o mais no meio ainda. E com poucos membros na fam√≠lia. Obviamente levando em conta uma igualdade de g√™neros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O que se confirma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, √© um pouco dif√≠cil identificar grupos √≥bvios (clusters), pois √© dif√≠cil combinar v√°rias vari√°veis simultaneamente (para analisar distribui√ß√µes multivariadas). √â a√≠ que √Ålgebra Linear e Aprendizado de M√°quina podem ser bastante √∫teis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 1. Clientes Similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na linguagem de AM, √© necess√°rio desenvolver um procedimento que retorne k vizinhos mais pr√≥ximos (objetos) para um determinado objeto com base na dist√¢ncia entre os objetos.\n",
    "Voc√™ pode querer rever as seguintes li√ß√µes (cap√≠tulo -> li√ß√£o)- Dist√¢ncia Entre Vetores -> Dist√¢ncia Euclidiana\n",
    "- Dist√¢ncia Entre Vetores -> Dist√¢ncia de Manhattan\n",
    "\n",
    "Para resolver a tarefa, podemos tentar diferentes m√©tricas de dist√¢ncia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escreva uma fun√ß√£o que retorne k vizinhos mais pr√≥ximos para um n-√©simo objeto com base em uma m√©trica de dist√¢ncia especificada. O n√∫mero de pagamentos de seguro recebidos n√£o deve ser levado em considera√ß√£o para esta tarefa. \n",
    "\n",
    "Voc√™ pode usar uma implementa√ß√£o pronta do algoritmo kNN do scikit-learn (verifique [o link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)) ou usar a sua pr√≥pria.\n",
    "Teste-o para quatro combina√ß√µes de dois casos\n",
    "- Escalabilidade\n",
    "  - os dados n√£o s√£o escalados\n",
    "  - os dados escalados com o escalonador [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html) \n",
    "- M√©tricas de dist√¢ncia\n",
    "  - Euclidiana\n",
    "  - Manhattan\n",
    "\n",
    "Responda √†s perguntas:\n",
    "- Os dados n√£o escalados afetam o algoritmo kNN? Se sim, como isso acontece?\n",
    "-Qu√£o semelhantes s√£o os resultados usando a m√©trica de dist√¢ncia de Manhattan (independentemente da escalabilidade)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(df, n, k, metric):\n",
    "    \n",
    "    \"\"\"\n",
    "    Retorna os vizinhos mais pr√≥ximos de k\n",
    "\n",
    "    :param df: DataFrame pandas usado para encontrar objetos semelhantes dentro de    :param n: n√∫mero do objeto pelo qual os vizinhos mais pr√≥ximos s√£o procurados\n",
    "    :param k: o n√∫mero dos vizinhos mais pr√≥ximos a serem retornados\n",
    "    :param metric: nome da m√©trica de dist√¢ncia    \"\"\"\n",
    "    \n",
    "    if metric == 'euclidean':\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "    elif metric == 'manhattan':\n",
    "        nbrs = NearestNeighbors(n_neighbors=k, metric='manhattan')\n",
    "    else:\n",
    "        raise ValueError(\"M√©trica n√£o suportada. Escolha 'euclidean' ou 'manhattan'\")\n",
    "\n",
    "   \n",
    "    nbrs = nbrs.fit(df[feature_names])\n",
    "   \n",
    "    nbrs_distances, nbrs_indices = nbrs.kneighbors([df.iloc[n][feature_names]], k, return_distance=True)\n",
    "    \n",
    "    df_res = pd.concat([\n",
    "        df.iloc[nbrs_indices[0]], \n",
    "        pd.DataFrame(nbrs_distances.T, index=nbrs_indices[0], columns=['distance'])\n",
    "        ], axis=1)\n",
    "    \n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['gender', 'age', 'income', 'family_members']\n",
    "\n",
    "transformer_mas = sklearn.preprocessing.MaxAbsScaler().fit(df[feature_names].to_numpy())\n",
    "\n",
    "df_scaled = df.copy()\n",
    "df_scaled.loc[:, feature_names] = transformer_mas.transform(df[feature_names].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos obter registros semelhantes para um determinado registro para cada combina√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df, 1, 10, 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df, 1, 10, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df_scaled, 1, 10, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(df_scaled, 1, 10, 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respostas para as perguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Os dados n√£o escalados afetam o algoritmo kNN? Se sim, como isso acontece?** \n",
    "\n",
    "Afetam sim, deixando a dist√¢ncia calculada maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As diferen√ßas de escala podem levar a uma maior influ√™ncia de algumas caracter√≠sticas em rela√ß√£o a outras. Por exemplo, se uma caracter√≠stica tiver valores muito maiores em compara√ß√£o com outras, ela dominar√° as dist√¢ncias calculadas pelo kNN, mesmo que outras caracter√≠sticas sejam mais relevantes para a tarefa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu√£o semelhantes s√£o os resultados usando a m√©trica de dist√¢ncia de Manhattan (independentemente da escalabilidade)?** \n",
    "\n",
    "Bem semelhantes, mas maiores que a dist√¢ncia euclidiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 2. √â prov√°vel que o cliente receba um pagamento do seguro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos de aprendizado de m√°quina, podemos olhar para isso como uma tarefa de classifica√ß√£o bin√°ria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os pagamentos de seguro sendo mais do que zero como objetivo, avalie se a abordagem da classifica√ß√£o kNN pode ser melhor do que um modelo dummy.\n",
    "\n",
    "Instru√ß√µes:\n",
    "- Construa um classificador baseado em kNN e me√ßa sua qualidade com a m√©trica F1 para k=1..10 tanto para os dados originais quanto para os escalados. Seria interessante ver como k pode influenciar a m√©trica de avalia√ß√£o e se a escalabilidade dos dados faz alguma diferen√ßa. Voc√™ pode usar uma implementa√ß√£o pronta do algoritmo de classifica√ß√£o kNN do scikit-learn (verifique [o link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)) ou usar a sua pr√≥pria.\n",
    "- Construa o modelo dummy, que √© aleat√≥rio para este caso. Deve retornar com alguma probabilidade o valor \"1\". LVamos testar o modelo com quatro valores de probabilidade: 0, a probabilidade de fazer qualquer pagamento de seguro, 0,5, 1.\n",
    "\n",
    "A probabilidade de fazer qualquer pagamento de seguro pode ser definida como\n",
    "\n",
    "$$\n",
    "P\\{\\text{pagamento de seguro recebido}= n√∫mero de clientes que receberam qualquer pagamento de seguro}}{\\text{n√∫mero total de clientes}}.\n",
    "$$\n",
    "\n",
    "Divida os dados inteiros na propor√ß√£o 70:30 para as partes de treinamento/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(insurance_benefits):\n",
    "    if insurance_benefits >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['insurance_benefits_received'] = df['insurance_benefits'].apply(update)\n",
    "df_scaled['insurance_benefits_received'] = df_scaled['insurance_benefits'].apply(update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifique o desequil√≠brio de classe com value_counts()\n",
    "\n",
    "display(df['insurance_benefits_received'].value_counts())\n",
    "df_scaled['insurance_benefits_received'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3, random_state=12345)\n",
    "\n",
    "df_train2, df_test2 = train_test_split(df_scaled, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = df_train.drop(['insurance_benefits_received','insurance_benefits'], axis=1)\n",
    "target_train = df_train['insurance_benefits_received']\n",
    "\n",
    "features_test = df_test.drop(['insurance_benefits_received','insurance_benefits'], axis=1)\n",
    "target_test = df_test['insurance_benefits_received']\n",
    "\n",
    "features_train2 = df_train2.drop(['insurance_benefits_received','insurance_benefits'], axis=1)\n",
    "target_train2 = df_train2['insurance_benefits_received']\n",
    "\n",
    "features_test2 = df_test2.drop(['insurance_benefits_received','insurance_benefits'], axis=1)\n",
    "target_test2 = df_test2['insurance_benefits_received'] \n",
    "\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)\n",
    "\n",
    "\n",
    "print(features_train2.shape)\n",
    "print(target_train2.shape)\n",
    "print(features_test2.shape)\n",
    "print(target_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(features_train, target_train)\n",
    "    test_predictions = model.predict(features_test)\n",
    "\n",
    "    model2 = KNeighborsClassifier(n_neighbors=i)\n",
    "    model2.fit(features_train2, target_train2)\n",
    "    test_predictions2 = model2.predict(features_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_classifier(y_true, y_pred):\n",
    "    \n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred)\n",
    "    print(f'F1: {f1_score:.2f}')\n",
    "    \n",
    "# se voc√™ tiver um problema com a linha a seguir, reinicie o kernel e execute o caderno novamente\n",
    "    cm = sklearn.metrics.confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    print('Matriz de Confus√£o')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando sa√≠da de um modelo aleat√≥rio\n",
    "\n",
    "def rnd_model_predict(P, size, seed=42):\n",
    "\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    return rng.binomial(n=1, p=P, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for P in [0, df['insurance_benefits_received'].sum() / len(df), 0.5, 1]:\n",
    "\n",
    "    print(f'A probabilidade: {P:.2f}')\n",
    "    y_pred_rnd = rnd_model_predict(P, size=len(df['insurance_benefits_received']))\n",
    "        \n",
    "    eval_classifier(df['insurance_benefits_received'], y_pred_rnd)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    print('k=',i)\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(features_train, target_train)\n",
    "    test_predictions = model.predict(features_test)\n",
    "    eval_classifier(target_test, test_predictions)\n",
    "    print('k scaled=',i)\n",
    "    model2 = KNeighborsClassifier(n_neighbors=i)\n",
    "    model2.fit(features_train2, target_train2)\n",
    "    test_predictions2 = model2.predict(features_test2)\n",
    "    eval_classifier(target_test2, test_predictions2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* O maior valor f1 encontrado foi com o par√¢metro k=1 com os dados *scaled*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 3. Regress√£o (com Regress√£o Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os pagamentos de seguro como objetivo, avalie qual seria o REQM para um modelo de Regress√£o Linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construa sua pr√≥pria implementa√ß√£o de Regress√£o Linear. Para isso, lembre-se de como a solu√ß√£o da tarefa de regress√£o linear √© formulada em termos de √Ålgebra linear. Verifique o REQM para os dados originais e os escalados. Voc√™ pode ver alguma diferen√ßa no REQM entre esses dois casos?\n",
    "\n",
    "Vamos denotar\n",
    "- $X$ ‚Äî matriz de caracter√≠sticas, cada linha √© um caso, cada coluna √© uma caracter√≠stica, a primeira coluna consiste em unidades\n",
    "- $y$ ‚Äî objetivo (um vetor)\n",
    "- $\\hat{y}$ ‚Äî objetivo estimado (um vetor)- $w$ ‚Äî vetor de peso\n",
    "\n",
    "A tarefa de regress√£o linear na linguagem de matrizes pode ser formulada como\n",
    "$$\n",
    "y = Xw\n",
    "$$\n",
    "\n",
    "O objetivo do treinamento, ent√£o, √© encontrar os $w$ que minimizaria a dist√¢ncia L2 (EQM) entre $Xw$ e $y$:\n",
    "\n",
    "$$\n",
    "\\min_w d_2(Xw, y) \\quad \\text{or} \\quad \\min_w \\text{MSE}(Xw, y)\n",
    "$$\n",
    "\n",
    "Parece que h√° uma solu√ß√£o anal√≠tica para a quest√£o acima:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "A f√≥rmula acima pode ser usada para encontrar os pesos $w$ e o √∫ltimo pode ser usado para calcular valores preditos\n",
    "\n",
    "$$\n",
    "\\hat{y} = X_{val}w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divida todos os dados na propor√ß√£o 70:30 para as partes de treinamento/valida√ß√£o. Use a m√©trica REQM para a avalia√ß√£o do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Adicionando uma coluna de uns para representar o termo de bias\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        \n",
    "        # Calculando os pesos usando a f√≥rmula dos m√≠nimos quadrados\n",
    "        self.weights = np.linalg.inv(X2.T @ X2) @ X2.T @ y\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Adicionando uma coluna de uns para representar o termo de bias\n",
    "        X2 = np.append(np.ones([len(X), 1]), X, axis=1)\n",
    "        \n",
    "        # Realizando a previs√£o usando os pesos aprendidos\n",
    "        y_pred = X2 @ self.weights\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regressor(y_true, y_pred):\n",
    "    \n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'REQM: {rmse:.2f}')\n",
    "    \n",
    "    r2_score = math.sqrt(sklearn.metrics.r2_score(y_true, y_pred))\n",
    "    print(f'R2: {r2_score:.2f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xx = df[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "y = df['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xx, y, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr = MyLinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.weights)\n",
    "\n",
    "y_test_pred = lr.predict(X_test)\n",
    "eval_regressor(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xxx = df_scaled[['age', 'gender', 'income', 'family_members']].to_numpy()\n",
    "yx = df_scaled['insurance_benefits'].to_numpy()\n",
    "\n",
    "X_trainx, X_testx, y_trainx, y_testx = train_test_split(Xxx, yx, test_size=0.3, random_state=12345)\n",
    "\n",
    "lrx = MyLinearRegression()\n",
    "\n",
    "lrx.fit(X_trainx, y_trainx)\n",
    "print(lrx.weights)\n",
    "\n",
    "y_test_predx = lrx.predict(X_testx)\n",
    "eval_regressor(y_testx, y_test_predx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sem diferen√ßa no REQM nesses dois casos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 4. Ofuscando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√â melhor ofuscar os dados multiplicando as caracter√≠sticas num√©ricas (lembre-se, elas podem ser vistos como a matriz $X$) por uma matriz invert√≠vel $P$. \n",
    "\n",
    "$$\n",
    "X' = X \\times P\n",
    "$$\n",
    "\n",
    "Tente fazer isso e verifique como os valores das caracter√≠sticas ficar√£o ap√≥s a transforma√ß√£o. Ali√°s, a invertibilidade √© importante aqui, portanto, certifique-se de que $P$ seja realmente invert√≠vel.\n",
    "\n",
    "Voc√™ pode querer revisar a li√ß√£o 'Matrizes e Opera√ß√µes com Matrizes -> Multiplica√ß√£o de Matrizes' para relembrar a regra de multiplica√ß√£o de matrizes e sua implementa√ß√£o com NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info_column_list = ['gender', 'age', 'income', 'family_members']\n",
    "df_pn = df[personal_info_column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz original\n",
    "X = df_pn.to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando uma matriz $P$ aleat√≥ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz aleatoria\n",
    "rng = np.random.default_rng(seed=42)\n",
    "P = rng.random(size=(X.shape[1], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando se a matriz $P$ √© invert√≠vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=np.linalg.inv(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voc√™ consegue adivinhar a idade ou a renda dos clientes ap√≥s a transforma√ß√£o?\n",
    "* N√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matriz transformada\n",
    "X1=X @ P\n",
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voc√™ pode recuperar os dados originais de $X‚Ä≤$ se souber $P$? Tente verificar isso com c√°lculos movendo $P$ do lado direito da f√≥rmula acima para o esquerdo. As regras da multiplica√ß√£o de matrizes s√£o realmente √∫teis aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XX=X1 @ p1\n",
    "XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima todos os tr√™s casos para alguns clientes- Os dados originais\n",
    "- O transformado\n",
    "- O invertido (recuperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(X,X1,XX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voc√™ provavelmente pode ver que alguns valores n√£o s√£o exatamente iguais aos dos dados originais. Qual pode ser a raz√£o disso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Acredito que se deve √† natureza das transforma√ß√µes aplicadas e √† complexidade dos algoritmos envolvidos. Por se tratar de uma matriz aleat√≥ria na ofusca√ß√£o e a inversa dela na recupera√ß√£o. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provas de que a ofusca√ß√£o de dados pode funcionar com a Regress√£o Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tarefa de regress√£o foi resolvida com regress√£o linear neste projeto. Sua pr√≥xima tarefa √© provar analiticamente que o m√©todo de ofusca√ß√£o fornecido n√£o afetar√° a regress√£o linear em termos de valores preditos, ou seja, seus valores permanecer√£o os mesmos. Voc√™ acredita nisso? Bem, voc√™ n√£o precisa acreditar, voc√™ deve provar isso!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, os dados s√£o ofuscados e h√° $X \\ P$ em vez de apenas X agora. Consequentemente, existem outros pesos $w_P$ como\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y \\quad \\Rightarrow \\quad w_P = [(XP)^T XP]^{-1} (XP)^T y\n",
    "$$\n",
    "\n",
    "Como  $w$ e $w_P$ seriam ligados se voc√™ simplificasse a f√≥rmula para $w_P$ acima? \n",
    "\n",
    "Quais seriam os valores previstos com $w_P$? \n",
    "\n",
    "O que isso significa para a qualidade da regress√£o linear se voc√™ medir com REQM?\n",
    "\n",
    "Verifique o Ap√™ndice B Propriedades das Matrizes no final do caderno. Existem f√≥rmulas √∫teis l√°!\n",
    "\n",
    "Nenhum c√≥digo √© necess√°rio nesta se√ß√£o, apenas explica√ß√£o anal√≠tica!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Para simplificar essa f√≥rmula, podemos usar a propriedade das matrizes que diz que <td>$(AB)^T = B^TA^T$</td>. Aplicando isso, podemos reescrever ùë§ùëÉ como <td>$$ùë§ùëÉ=(ùëãùëÉ)^{-1}(ùëãùëÉ)^ùëáùë¶$$</td>.\n",
    "\n",
    "2- Para calcular os valores previstos com ùë§ùëÉ, voc√™ multiplica a matriz de caracter√≠sticas ùëãùëÉ pelos pesos ùë§ùëÉ. Ou seja, os valores previstos ùë¶ÃÇùëÉ seriam <td>$$ùë¶ÃÇùëÉ=ùëãùëÉùë§ùëÉ$$</td>.\n",
    "\n",
    "3- O REQM (Raiz do Erro Quadr√°tico M√©dio) √© uma medida comum de qualidade para avaliar a efic√°cia de um modelo de regress√£o. Portanto, se o REQM for menor, significa que os valores previstos est√£o mais pr√≥ximos dos valores reais, o que indica uma melhor qualidade da regress√£o linear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prova anal√≠tica**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td>\n",
    "$$\n",
    "w=(X^{T}X)^{-1}X^{T}y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = [(XP)^{T}(XP)]^{-1}(XP)^{T}y\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_P = [(P^{T}X^{T})(XP)]^{-1}(XP)^{T}y,\n",
    "$$\n",
    "\n",
    "Usando a propriedade de reversividade da transposi√ß√£o de um produto de matrizes, assim conseguimos passar de $(XP)^{T}$ para $(P^{T}X^{T})$.\n",
    "\n",
    "Ap√≥s esse passo, podemos aplicar a inversa num produto matricial junto da propriedade associativa da multiplica√ß√£o,\n",
    "\n",
    "$$\n",
    "w_P = [P^{T}(X^{T}X)P]^{-1}(XP)^{T}y = P^{-1}(X^{T}X)^{-1}(P^{T})^{-1}P^{T}(X^{T}y).\n",
    "$$\n",
    "    \n",
    "Antes do termo $(X^{T}y)$ temos o termo $(P^{T})^{-1}P^{T}$, por√©m pela propriedade da identidade multiplicativa, temos que:\n",
    "    \n",
    "$$\n",
    "(P^{T})^{-1}P^{T} = I,\n",
    "$$\n",
    "\n",
    "Continuando:\n",
    "‚Äã\n",
    "$$\n",
    "w_P = P^{-1}(X^{T}X)^{-1}(P^{T})^{-1}P^{T}(X^{T}y) = P^{-1}(X^{T}X)^{-1}I(X^{T}y) = P^{-1}(X^{T}X)^{-1}(X^{T}y).\n",
    "$$\n",
    "    \n",
    "Bem, se $w = (X^{T}X)^{-1}X^{T}y$, ent√£o:\n",
    "    \n",
    "$$\n",
    "w_P = P^{-1}(X^{T}X)^{-1}(X^{T}y) = P^{-1}w,\n",
    "$$\n",
    "    \n",
    "logo a matriz $A$ desconhecida √© igual a $P^{-1}$ e:\n",
    "    \n",
    "$$\n",
    "w_P = P^{-1}w.\n",
    "$$\n",
    "‚Äã\n",
    "Para demonstrar de forma anal√≠tica que a ofusca√ß√£o de dados n√£o afeta a regress√£o linear, √© suficiente substituir o valor de ùë§ùëÉ\n",
    "na equa√ß√£o a seguir pela rela√ß√£o previamente estabelecida:\n",
    "    \n",
    "$$\n",
    "\\hat{y_P} = (X_{val}P)w_P = X_{val}PP^{-1}w,\n",
    "$$\n",
    "    \n",
    "pela propriedade da identidade multiplicativa, temos que:\n",
    "‚Äã\n",
    "$$\n",
    "\\hat{y_P} = X_{val}PP^{-1}w = X_{val}Iw = X_{val}w = \\hat{y}.\n",
    "$$\n",
    "    \n",
    "Assim, demonstramos que $\\hat{y_P} = \\hat{y}$, o que implica que a ofusca√ß√£o de dados n√£o tem efeito sobre a previs√£o realizada, embora possa modificar os coeficientes estimados. Como resultado, uma vez que a previs√£o permanece inalterada, nenhuma m√©trica de erro sofrer√° modifica√ß√£o.\n",
    "</td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_w(X, y):\n",
    "    XTX_inv = np.linalg.inv(np.dot(X.T, X))\n",
    "    w = np.dot(np.dot(XTX_inv, X.T), y)\n",
    "    return w\n",
    "\n",
    "def calculate_wP(XP, y):\n",
    "    wP = np.dot(np.dot(np.linalg.inv(np.dot(XP.T, XP)), XP.T), y)\n",
    "    return wP\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "XP = Xx + 1 #ex de dados ofuscados \n",
    "\n",
    "w = calculate_w(Xx, y)\n",
    "wP = calculate_wP(XP, y)\n",
    "\n",
    "print(\"w:\", w)\n",
    "print(\"wP:\", wP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_values(X, w):\n",
    "    y_pred = np.dot(X, w)\n",
    "    return y_pred\n",
    "\n",
    "def predict_values_P(XP, wP):\n",
    "    y_pred_P = np.dot(XP, wP)\n",
    "    return y_pred_P\n",
    "\n",
    "# Exemplo de uso\n",
    "y_pred = predict_values(Xx, w)\n",
    "y_pred_P = predict_values_P(XP, wP)\n",
    "\n",
    "print(\"y_pred:\", y_pred)\n",
    "print(\"y_pred_P:\", y_pred_P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_RMSE(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# Exemplo de uso\n",
    "RMSE_w = calculate_RMSE(y, y_pred)\n",
    "RMSE_wP = calculate_RMSE(y, y_pred_P)\n",
    "\n",
    "print(\"RMSE for w:\", RMSE_w)\n",
    "print(\"RMSE for wP:\", RMSE_wP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de regress√£o linear com ofusca√ß√£o de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos provar que a Regress√£o Linear pode funcionar computacionalmente com a transforma√ß√£o de ofusca√ß√£o escolhida.\n",
    "Crie um procedimento ou uma classe que execute a Regress√£o Linear opcionalmente com a ofusca√ß√£o. Voc√™ pode usar uma implementa√ß√£o pronta de Regress√£o Linear do scikit-learn ou sua pr√≥pria.\n",
    "\n",
    "Execute a Regress√£o Linear para os dados originais e os ofuscados, compare os valores previstos e os valores da m√©trica $R^2$ do REQM. H√° alguma diferen√ßa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedimento**\n",
    "\n",
    "- Crie uma matriz quadrada $P$ de n√∫meros aleat√≥rios.\n",
    "- Verifique se √© invert√≠vel. Caso contr√°rio, repita o primeiro ponto at√© obtermos uma matriz invert√≠vel.\n",
    "- <! seu coment√°rio aqui!>\n",
    "- Use $XP$ como a nova matriz de caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev(y_true,y_pred):\n",
    "    rmse = math.sqrt(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "    print(f'REQM: {rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=df[['age', 'gender', 'income', 'family_members']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B=df_scaled[['age', 'gender', 'income', 'family_members']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "Pw = rng.random(size=(G.shape[1], G.shape[1]))\n",
    "Pw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "Pb = rng.random(size=(B.shape[1], B.shape[1]))\n",
    "Pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oo = np.linalg.inv(Pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=np.linalg.inv(Pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo=G@oo\n",
    "mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb=B@bb\n",
    "mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = mo\n",
    "y1 = G\n",
    "\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x1, y1, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr1 = MyLinearRegression()\n",
    "\n",
    "lr1.fit(X_train1, y_train1)\n",
    "print(lr1.weights)\n",
    "\n",
    "ev(y_train1, lr1.predict(X_train1))\n",
    "ev(y_test1, lr1.predict(X_test1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1.fit(X_test1, y_test1)\n",
    "ev(y_train1, lr1.predict(X_train1))\n",
    "ev(y_test1, lr1.predict(X_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = mb\n",
    "y2 = B\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.3, random_state=12345)\n",
    "\n",
    "lr2 = MyLinearRegression()\n",
    "\n",
    "lr2.fit(X_train2, y_train2)\n",
    "print(lr2.weights)\n",
    "ev(y_train2, lr2.predict(X_train2))\n",
    "ev(y_test2, lr2.predict(X_test2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.fit(X_test2, y_test2)\n",
    "ev(y_train2, lr2.predict(X_train2))\n",
    "ev(y_test2, lr2.predict(X_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclus√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* N√£o existe grupos muito claros, por√©m em um gr√°fico 3d da para ter uma no√ß√£o melhor de como o dataframe se comporta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Escalamento de dados melhora o desempenho do Knn, e normalmente de todos os testes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A Prova que o REQM n√£o muda com a ofusca√ß√£o de dados foi feita."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "√çndice",
   "title_sidebar": "Conte√∫dos ",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "364.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
